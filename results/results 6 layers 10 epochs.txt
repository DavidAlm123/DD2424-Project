  Train Batch 81/582, Loss: 3.3090, Speed: 2.02 batches/sec
  Train Batch 101/582, Loss: 3.3142, Speed: 1.93 batches/sec
  Train Batch 121/582, Loss: 3.3446, Speed: 1.78 batches/sec
  Train Batch 141/582, Loss: 3.3288, Speed: 1.72 batches/sec
  Train Batch 161/582, Loss: 3.4094, Speed: 1.75 batches/sec
  Train Batch 181/582, Loss: 3.3023, Speed: 1.19 batches/sec
  Train Batch 201/582, Loss: 3.3026, Speed: 1.88 batches/sec
  Train Batch 221/582, Loss: 3.3198, Speed: 1.89 batches/sec
  Train Batch 241/582, Loss: 3.3090, Speed: 1.72 batches/sec
  Train Batch 261/582, Loss: 3.3174, Speed: 1.91 batches/sec
  Train Batch 281/582, Loss: 3.3060, Speed: 1.70 batches/sec
  Train Batch 301/582, Loss: 3.3211, Speed: 1.58 batches/sec
  Train Batch 321/582, Loss: 3.3765, Speed: 1.77 batches/sec
  Train Batch 341/582, Loss: 3.3153, Speed: 1.66 batches/sec
  Train Batch 361/582, Loss: 3.3189, Speed: 1.34 batches/sec
  Train Batch 381/582, Loss: 3.3720, Speed: 0.96 batches/sec
  Train Batch 401/582, Loss: 3.2994, Speed: 1.49 batches/sec
  Train Batch 421/582, Loss: 3.3391, Speed: 1.39 batches/sec
  Train Batch 441/582, Loss: 3.3662, Speed: 1.46 batches/sec
  Train Batch 461/582, Loss: 3.3123, Speed: 1.63 batches/sec
  Train Batch 481/582, Loss: 3.2925, Speed: 1.63 batches/sec
  Train Batch 501/582, Loss: 3.2971, Speed: 1.81 batches/sec
  Train Batch 521/582, Loss: 3.3534, Speed: 1.67 batches/sec
  Train Batch 541/582, Loss: 3.3371, Speed: 1.36 batches/sec
  Train Batch 561/582, Loss: 3.3274, Speed: 1.58 batches/sec
  Train Batch 581/582, Loss: 3.3256, Speed: 1.67 batches/sec
Epoch 9 Training - Avg Loss: 3.3240, Time: 358.18 sec
Epoch 9 Validation - Avg Loss: 3.3417, Avg Accuracy: 0.1507, Time: 7.88 sec

Epoch 10/20
  Train Batch 1/582, Loss: 3.2951, Speed: 0.69 batches/sec
  Train Batch 21/582, Loss: 3.3013, Speed: 1.78 batches/sec
  Train Batch 41/582, Loss: 3.3118, Speed: 1.82 batches/sec
  Train Batch 61/582, Loss: 3.3013, Speed: 1.36 batches/sec
  Train Batch 81/582, Loss: 3.3141, Speed: 1.77 batches/sec
  Train Batch 101/582, Loss: 3.3497, Speed: 1.72 batches/sec
  Train Batch 121/582, Loss: 3.2892, Speed: 1.80 batches/sec
  Train Batch 141/582, Loss: 3.2805, Speed: 1.68 batches/sec
  Train Batch 161/582, Loss: 3.3926, Speed: 1.70 batches/sec
  Train Batch 181/582, Loss: 3.3622, Speed: 1.36 batches/sec
  Train Batch 201/582, Loss: 3.3234, Speed: 1.84 batches/sec
  Train Batch 221/582, Loss: 3.3527, Speed: 1.62 batches/sec
  Train Batch 241/582, Loss: 3.2827, Speed: 1.87 batches/sec
  Train Batch 261/582, Loss: 3.3069, Speed: 1.72 batches/sec
  Train Batch 281/582, Loss: 3.3517, Speed: 1.78 batches/sec
  Train Batch 301/582, Loss: 3.3053, Speed: 1.80 batches/sec
  Train Batch 321/582, Loss: 3.3496, Speed: 1.84 batches/sec
  Train Batch 341/582, Loss: 3.3687, Speed: 2.03 batches/sec
  Train Batch 361/582, Loss: 3.3722, Speed: 1.52 batches/sec
  Train Batch 381/582, Loss: 3.3605, Speed: 1.67 batches/sec
  Train Batch 401/582, Loss: 3.3152, Speed: 1.26 batches/sec
  Train Batch 421/582, Loss: 3.3251, Speed: 1.24 batches/sec
  Train Batch 441/582, Loss: 3.3299, Speed: 1.68 batches/sec
  Train Batch 461/582, Loss: 3.3150, Speed: 1.79 batches/sec
  Train Batch 481/582, Loss: 3.3864, Speed: 1.76 batches/sec
  Train Batch 501/582, Loss: 3.2847, Speed: 1.47 batches/sec
  Train Batch 521/582, Loss: 3.3112, Speed: 1.72 batches/sec
  Train Batch 541/582, Loss: 3.3475, Speed: 1.62 batches/sec
  Train Batch 561/582, Loss: 3.3166, Speed: 1.77 batches/sec
  Train Batch 581/582, Loss: 3.3346, Speed: 1.49 batches/sec
Epoch 10 Training - Avg Loss: 3.3237, Time: 364.03 sec
Epoch 10 Validation - Avg Loss: 3.3387, Avg Accuracy: 0.1507, Time: 8.38 sec

Epoch 11/20
  Train Batch 1/582, Loss: 3.3437, Speed: 0.58 batches/sec
  Train Batch 21/582, Loss: 3.3170, Speed: 1.72 batches/sec
  Train Batch 41/582, Loss: 3.3110, Speed: 1.37 batches/sec
  Train Batch 61/582, Loss: 3.2993, Speed: 1.51 batches/sec
  Train Batch 81/582, Loss: 3.3215, Speed: 1.63 batches/sec
  Train Batch 101/582, Loss: 3.2962, Speed: 0.73 batches/sec
  Train Batch 121/582, Loss: 3.3683, Speed: 1.21 batches/sec
  Train Batch 141/582, Loss: 3.2966, Speed: 1.70 batches/sec
  Train Batch 161/582, Loss: 3.3204, Speed: 1.53 batches/sec
  Train Batch 181/582, Loss: 3.2888, Speed: 0.95 batches/sec
  Train Batch 201/582, Loss: 3.2752, Speed: 1.74 batches/sec
  Train Batch 221/582, Loss: 3.3234, Speed: 1.77 batches/sec
  Train Batch 241/582, Loss: 3.3115, Speed: 1.75 batches/sec
  Train Batch 261/582, Loss: 3.3065, Speed: 1.77 batches/sec
  Train Batch 281/582, Loss: 3.3273, Speed: 1.79 batches/sec
  Train Batch 301/582, Loss: 3.3336, Speed: 1.80 batches/sec
  Train Batch 321/582, Loss: 3.3166, Speed: 1.89 batches/sec
  Train Batch 341/582, Loss: 3.3155, Speed: 1.79 batches/sec
  Train Batch 361/582, Loss: 3.3142, Speed: 1.61 batches/sec
  Train Batch 381/582, Loss: 3.3289, Speed: 1.04 batches/sec
  Train Batch 401/582, Loss: 3.3163, Speed: 1.76 batches/sec
  Train Batch 421/582, Loss: 3.3349, Speed: 1.52 batches/sec
  Train Batch 441/582, Loss: 3.3352, Speed: 1.70 batches/sec
  Train Batch 461/582, Loss: 3.2603, Speed: 1.59 batches/sec
  Train Batch 481/582, Loss: 3.3420, Speed: 1.85 batches/sec
  Train Batch 501/582, Loss: 3.3151, Speed: 1.17 batches/sec
  Train Batch 521/582, Loss: 3.3110, Speed: 1.59 batches/sec
  Train Batch 541/582, Loss: 3.2971, Speed: 1.46 batches/sec
  Train Batch 561/582, Loss: 3.3122, Speed: 1.38 batches/sec
  Train Batch 581/582, Loss: 3.3152, Speed: 1.65 batches/sec
Epoch 11 Training - Avg Loss: 3.3234, Time: 378.69 sec
Epoch 11 Validation - Avg Loss: 3.3392, Avg Accuracy: 0.1507, Time: 7.89 sec

Epoch 12/20
  Train Batch 1/582, Loss: 3.2943, Speed: 1.09 batches/sec
  Train Batch 21/582, Loss: 3.2802, Speed: 1.72 batches/sec
  Train Batch 41/582, Loss: 3.3140, Speed: 1.62 batches/sec
  Train Batch 61/582, Loss: 3.2468, Speed: 1.53 batches/sec
  Train Batch 81/582, Loss: 3.3019, Speed: 1.64 batches/sec
  Train Batch 101/582, Loss: 3.3207, Speed: 1.43 batches/sec
  Train Batch 121/582, Loss: 3.3277, Speed: 0.52 batches/sec
  Train Batch 141/582, Loss: 3.3174, Speed: 1.49 batches/sec
  Train Batch 161/582, Loss: 3.3010, Speed: 1.27 batches/sec
  Train Batch 181/582, Loss: 3.3262, Speed: 1.55 batches/sec
  Train Batch 201/582, Loss: 3.3236, Speed: 1.75 batches/sec
  Train Batch 221/582, Loss: 3.3139, Speed: 1.73 batches/sec
  Train Batch 241/582, Loss: 3.3405, Speed: 1.64 batches/sec
  Train Batch 261/582, Loss: 3.3561, Speed: 1.60 batches/sec
  Train Batch 281/582, Loss: 3.2853, Speed: 1.65 batches/sec
  Train Batch 301/582, Loss: 3.3256, Speed: 1.46 batches/sec
  Train Batch 321/582, Loss: 3.3456, Speed: 1.67 batches/sec
  Train Batch 341/582, Loss: 3.3531, Speed: 1.73 batches/sec
  Train Batch 361/582, Loss: 3.3246, Speed: 1.77 batches/sec
  Train Batch 381/582, Loss: 3.3572, Speed: 1.54 batches/sec
  Train Batch 401/582, Loss: 3.3262, Speed: 1.55 batches/sec
  Train Batch 421/582, Loss: 3.3212, Speed: 1.77 batches/sec
  Train Batch 441/582, Loss: 3.3382, Speed: 1.81 batches/sec
  Train Batch 461/582, Loss: 3.3440, Speed: 1.73 batches/sec
  Train Batch 481/582, Loss: 3.3323, Speed: 1.82 batches/sec
  Train Batch 501/582, Loss: 3.3359, Speed: 1.91 batches/sec
  Train Batch 521/582, Loss: 3.3428, Speed: 2.03 batches/sec
  Train Batch 541/582, Loss: 3.3718, Speed: 1.98 batches/sec
  Train Batch 561/582, Loss: 3.3044, Speed: 2.02 batches/sec
  Train Batch 581/582, Loss: 3.3560, Speed: 2.13 batches/sec
Epoch 12 Training - Avg Loss: 3.3235, Time: 386.91 sec
Epoch 12 Validation - Avg Loss: 3.3390, Avg Accuracy: 0.1507, Time: 5.80 sec

Epoch 13/20
  Train Batch 1/582, Loss: 3.2960, Speed: 1.92 batches/sec
  Train Batch 21/582, Loss: 3.2972, Speed: 2.20 batches/sec
  Train Batch 41/582, Loss: 3.2979, Speed: 2.15 batches/sec
  Train Batch 61/582, Loss: 3.3019, Speed: 2.21 batches/sec
  Train Batch 81/582, Loss: 3.3420, Speed: 2.17 batches/sec
  Train Batch 101/582, Loss: 3.2942, Speed: 2.42 batches/sec
  Train Batch 121/582, Loss: 3.2797, Speed: 1.67 batches/sec
  Train Batch 141/582, Loss: 3.3725, Speed: 2.24 batches/sec
  Train Batch 161/582, Loss: 3.3133, Speed: 1.83 batches/sec
  Train Batch 181/582, Loss: 3.3558, Speed: 2.20 batches/sec
  Train Batch 201/582, Loss: 3.3185, Speed: 2.21 batches/sec
  Train Batch 221/582, Loss: 3.3181, Speed: 2.09 batches/sec
  Train Batch 241/582, Loss: 3.3340, Speed: 1.81 batches/sec
  Train Batch 261/582, Loss: 3.2970, Speed: 2.14 batches/sec
  Train Batch 281/582, Loss: 3.3438, Speed: 2.03 batches/sec
  Train Batch 301/582, Loss: 3.2762, Speed: 2.40 batches/sec
  Train Batch 321/582, Loss: 3.2981, Speed: 1.94 batches/sec
  Train Batch 341/582, Loss: 3.3230, Speed: 2.01 batches/sec
  Train Batch 361/582, Loss: 3.3182, Speed: 2.00 batches/sec
  Train Batch 381/582, Loss: 3.2911, Speed: 2.15 batches/sec
  Train Batch 401/582, Loss: 3.2906, Speed: 1.64 batches/sec
  Train Batch 421/582, Loss: 3.3171, Speed: 2.22 batches/sec
  Train Batch 441/582, Loss: 3.2883, Speed: 2.08 batches/sec
  Train Batch 461/582, Loss: 3.3326, Speed: 2.36 batches/sec
  Train Batch 481/582, Loss: 3.2814, Speed: 2.00 batches/sec
  Train Batch 501/582, Loss: 3.3277, Speed: 2.19 batches/sec
  Train Batch 521/582, Loss: 3.3630, Speed: 2.24 batches/sec
  Train Batch 541/582, Loss: 3.3163, Speed: 2.24 batches/sec
  Train Batch 561/582, Loss: 3.3196, Speed: 1.73 batches/sec
  Train Batch 581/582, Loss: 3.3230, Speed: 2.61 batches/sec
Epoch 13 Training - Avg Loss: 3.3246, Time: 281.19 sec
Epoch 13 Validation - Avg Loss: 3.3383, Avg Accuracy: 0.1507, Time: 5.47 sec

Epoch 14/20
  Train Batch 1/582, Loss: 3.2876, Speed: 1.68 batches/sec
  Train Batch 21/582, Loss: 3.3180, Speed: 2.25 batches/sec
  Train Batch 41/582, Loss: 3.3164, Speed: 2.29 batches/sec
  Train Batch 61/582, Loss: 3.3067, Speed: 1.89 batches/sec
  Train Batch 81/582, Loss: 3.2814, Speed: 2.34 batches/sec
  Train Batch 101/582, Loss: 3.2883, Speed: 2.33 batches/sec
  Train Batch 121/582, Loss: 3.3096, Speed: 2.26 batches/sec
  Train Batch 141/582, Loss: 3.3495, Speed: 2.09 batches/sec
  Train Batch 161/582, Loss: 3.3297, Speed: 1.97 batches/sec
  Train Batch 181/582, Loss: 3.3374, Speed: 1.45 batches/sec
  Train Batch 201/582, Loss: 3.3260, Speed: 1.89 batches/sec
  Train Batch 221/582, Loss: 3.3570, Speed: 2.17 batches/sec
  Train Batch 241/582, Loss: 3.3457, Speed: 2.02 batches/sec
  Train Batch 261/582, Loss: 3.3368, Speed: 2.15 batches/sec
  Train Batch 281/582, Loss: 3.3106, Speed: 1.93 batches/sec
  Train Batch 301/582, Loss: 3.3465, Speed: 2.02 batches/sec
  Train Batch 321/582, Loss: 3.3348, Speed: 1.32 batches/sec
  Train Batch 341/582, Loss: 3.3292, Speed: 2.04 batches/sec
  Train Batch 361/582, Loss: 3.3348, Speed: 2.18 batches/sec
  Train Batch 381/582, Loss: 3.3104, Speed: 2.21 batches/sec
  Train Batch 401/582, Loss: 3.3198, Speed: 2.09 batches/sec
  Train Batch 421/582, Loss: 3.3234, Speed: 2.16 batches/sec
  Train Batch 441/582, Loss: 3.3245, Speed: 2.38 batches/sec
  Train Batch 461/582, Loss: 3.3273, Speed: 2.54 batches/sec
  Train Batch 481/582, Loss: 3.3523, Speed: 2.62 batches/sec
  Train Batch 501/582, Loss: 3.3546, Speed: 2.41 batches/sec
  Train Batch 521/582, Loss: 3.3541, Speed: 1.73 batches/sec
  Train Batch 541/582, Loss: 3.3217, Speed: 2.35 batches/sec
  Train Batch 561/582, Loss: 3.3183, Speed: 2.38 batches/sec
  Train Batch 581/582, Loss: 3.3374, Speed: 2.23 batches/sec
Epoch 14 Training - Avg Loss: 3.3244, Time: 285.48 sec
Epoch 14 Validation - Avg Loss: 3.3405, Avg Accuracy: 0.1507, Time: 4.86 sec

Epoch 15/20
  Train Batch 1/582, Loss: 3.3240, Speed: 2.14 batches/sec
  Train Batch 21/582, Loss: 3.2777, Speed: 2.41 batches/sec
  Train Batch 41/582, Loss: 3.3358, Speed: 2.05 batches/sec
  Train Batch 61/582, Loss: 3.2758, Speed: 2.11 batches/sec
  Train Batch 81/582, Loss: 3.2938, Speed: 1.94 batches/sec
  Train Batch 101/582, Loss: 3.3119, Speed: 2.28 batches/sec
  Train Batch 121/582, Loss: 3.3098, Speed: 1.99 batches/sec
  Train Batch 141/582, Loss: 3.3396, Speed: 2.30 batches/sec
  Train Batch 161/582, Loss: 3.2832, Speed: 1.87 batches/sec
  Train Batch 181/582, Loss: 3.2769, Speed: 1.76 batches/sec
  Train Batch 201/582, Loss: 3.3248, Speed: 2.31 batches/sec
  Train Batch 221/582, Loss: 3.3236, Speed: 2.49 batches/sec
  Train Batch 241/582, Loss: 3.3354, Speed: 2.12 batches/sec
  Train Batch 261/582, Loss: 3.2934, Speed: 2.53 batches/sec
  Train Batch 281/582, Loss: 3.3597, Speed: 2.11 batches/sec
  Train Batch 301/582, Loss: 3.3440, Speed: 1.92 batches/sec
  Train Batch 321/582, Loss: 3.3132, Speed: 2.20 batches/sec
  Train Batch 341/582, Loss: 3.3280, Speed: 2.47 batches/sec
  Train Batch 361/582, Loss: 3.2893, Speed: 2.28 batches/sec
  Train Batch 381/582, Loss: 3.3343, Speed: 2.48 batches/sec
  Train Batch 401/582, Loss: 3.3683, Speed: 1.73 batches/sec
  Train Batch 421/582, Loss: 3.3661, Speed: 2.45 batches/sec
  Train Batch 441/582, Loss: 3.3281, Speed: 2.29 batches/sec
  Train Batch 461/582, Loss: 3.3006, Speed: 2.16 batches/sec
  Train Batch 481/582, Loss: 3.3050, Speed: 1.44 batches/sec
  Train Batch 501/582, Loss: 3.3300, Speed: 2.51 batches/sec
  Train Batch 521/582, Loss: 3.3508, Speed: 2.42 batches/sec
  Train Batch 541/582, Loss: 3.3661, Speed: 2.05 batches/sec
  Train Batch 561/582, Loss: 3.3108, Speed: 2.48 batches/sec
  Train Batch 581/582, Loss: 3.3403, Speed: 2.57 batches/sec
Epoch 15 Training - Avg Loss: 3.3242, Time: 270.17 sec
Epoch 15 Validation - Avg Loss: 3.3403, Avg Accuracy: 0.1507, Time: 4.80 sec

Epoch 16/20
  Train Batch 1/582, Loss: 3.3344, Speed: 2.42 batches/sec
  Train Batch 21/582, Loss: 3.2912, Speed: 2.48 batches/sec
  Train Batch 41/582, Loss: 3.2861, Speed: 2.61 batches/sec
  Train Batch 61/582, Loss: 3.2974, Speed: 2.56 batches/sec
  Train Batch 81/582, Loss: 3.2687, Speed: 2.23 batches/sec
  Train Batch 101/582, Loss: 3.3032, Speed: 2.02 batches/sec
  Train Batch 121/582, Loss: 3.3449, Speed: 2.10 batches/sec
  Train Batch 141/582, Loss: 3.3727, Speed: 2.28 batches/sec
  Train Batch 161/582, Loss: 3.3372, Speed: 2.13 batches/sec
  Train Batch 181/582, Loss: 3.3410, Speed: 2.26 batches/sec
  Train Batch 201/582, Loss: 3.3003, Speed: 2.09 batches/sec
  Train Batch 221/582, Loss: 3.3160, Speed: 2.37 batches/sec
  Train Batch 241/582, Loss: 3.3024, Speed: 2.16 batches/sec
  Train Batch 261/582, Loss: 3.3328, Speed: 2.33 batches/sec
  Train Batch 281/582, Loss: 3.3114, Speed: 2.30 batches/sec
  Train Batch 301/582, Loss: 3.3484, Speed: 2.26 batches/sec
  Train Batch 321/582, Loss: 3.3292, Speed: 2.17 batches/sec
  Train Batch 341/582, Loss: 3.3044, Speed: 1.67 batches/sec
  Train Batch 361/582, Loss: 3.3573, Speed: 1.77 batches/sec
  Train Batch 381/582, Loss: 3.3167, Speed: 1.58 batches/sec
  Train Batch 401/582, Loss: 3.2966, Speed: 2.03 batches/sec
  Train Batch 421/582, Loss: 3.3073, Speed: 2.28 batches/sec
  Train Batch 441/582, Loss: 3.2853, Speed: 2.35 batches/sec
  Train Batch 461/582, Loss: 3.3396, Speed: 2.57 batches/sec
  Train Batch 481/582, Loss: 3.3524, Speed: 2.31 batches/sec
  Train Batch 501/582, Loss: 3.2942, Speed: 2.07 batches/sec
  Train Batch 521/582, Loss: 3.3371, Speed: 2.43 batches/sec
  Train Batch 541/582, Loss: 3.3210, Speed: 2.28 batches/sec
  Train Batch 561/582, Loss: 3.3520, Speed: 2.59 batches/sec
  Train Batch 581/582, Loss: 3.3498, Speed: 2.25 batches/sec
Epoch 16 Training - Avg Loss: 3.3240, Time: 270.51 sec
2025-05-17 18:32:02.234527: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
Epoch 16 Validation - Avg Loss: 3.3409, Avg Accuracy: 0.1507, Time: 5.00 sec

Epoch 17/20
  Train Batch 1/582, Loss: 3.3742, Speed: 2.21 batches/sec
  Train Batch 21/582, Loss: 3.3478, Speed: 2.29 batches/sec
  Train Batch 41/582, Loss: 3.2944, Speed: 2.20 batches/sec
  Train Batch 61/582, Loss: 3.2264, Speed: 2.20 batches/sec
  Train Batch 81/582, Loss: 3.3627, Speed: 2.27 batches/sec
  Train Batch 101/582, Loss: 3.2710, Speed: 2.11 batches/sec
  Train Batch 121/582, Loss: 3.2922, Speed: 2.35 batches/sec
  Train Batch 141/582, Loss: 3.3278, Speed: 2.33 batches/sec
  Train Batch 161/582, Loss: 3.2868, Speed: 2.07 batches/sec
  Train Batch 181/582, Loss: 3.3040, Speed: 2.19 batches/sec
  Train Batch 201/582, Loss: 3.3134, Speed: 1.72 batches/sec
  Train Batch 221/582, Loss: 3.2906, Speed: 2.07 batches/sec
  Train Batch 241/582, Loss: 3.3348, Speed: 2.30 batches/sec
  Train Batch 261/582, Loss: 3.3076, Speed: 2.16 batches/sec
  Train Batch 281/582, Loss: 3.3742, Speed: 2.23 batches/sec
  Train Batch 301/582, Loss: 3.3701, Speed: 2.39 batches/sec
  Train Batch 321/582, Loss: 3.3010, Speed: 2.27 batches/sec
  Train Batch 341/582, Loss: 3.2979, Speed: 2.39 batches/sec
  Train Batch 361/582, Loss: 3.3383, Speed: 2.29 batches/sec
  Train Batch 381/582, Loss: 3.3299, Speed: 1.51 batches/sec
  Train Batch 401/582, Loss: 3.3300, Speed: 1.97 batches/sec
  Train Batch 421/582, Loss: 3.2956, Speed: 2.26 batches/sec
  Train Batch 441/582, Loss: 3.2984, Speed: 1.98 batches/sec
  Train Batch 461/582, Loss: 3.3002, Speed: 2.35 batches/sec
  Train Batch 481/582, Loss: 3.3390, Speed: 1.54 batches/sec
  Train Batch 501/582, Loss: 3.3228, Speed: 2.45 batches/sec
  Train Batch 521/582, Loss: 3.3790, Speed: 2.30 batches/sec
  Train Batch 541/582, Loss: 3.3005, Speed: 1.65 batches/sec
  Train Batch 561/582, Loss: 3.2854, Speed: 1.71 batches/sec
  Train Batch 581/582, Loss: 3.3412, Speed: 1.99 batches/sec
Epoch 17 Training - Avg Loss: 3.3239, Time: 281.12 sec
Epoch 17 Validation - Avg Loss: 3.3400, Avg Accuracy: 0.1507, Time: 4.85 sec

Epoch 18/20
  Train Batch 1/582, Loss: 3.2651, Speed: 2.16 batches/sec
  Train Batch 21/582, Loss: 3.2960, Speed: 2.38 batches/sec
  Train Batch 41/582, Loss: 3.3004, Speed: 2.24 batches/sec
  Train Batch 61/582, Loss: 3.3524, Speed: 2.43 batches/sec
  Train Batch 81/582, Loss: 3.3578, Speed: 2.55 batches/sec
  Train Batch 101/582, Loss: 3.3426, Speed: 2.52 batches/sec
  Train Batch 121/582, Loss: 3.3260, Speed: 2.23 batches/sec
  Train Batch 141/582, Loss: 3.3202, Speed: 2.42 batches/sec
  Train Batch 161/582, Loss: 3.3345, Speed: 2.14 batches/sec
  Train Batch 181/582, Loss: 3.3306, Speed: 2.27 batches/sec
  Train Batch 201/582, Loss: 3.3120, Speed: 2.35 batches/sec
  Train Batch 221/582, Loss: 3.3098, Speed: 2.41 batches/sec
  Train Batch 241/582, Loss: 3.3299, Speed: 2.42 batches/sec
  Train Batch 261/582, Loss: 3.3123, Speed: 1.53 batches/sec
  Train Batch 281/582, Loss: 3.3120, Speed: 2.26 batches/sec
  Train Batch 301/582, Loss: 3.3463, Speed: 2.40 batches/sec
  Train Batch 321/582, Loss: 3.3322, Speed: 2.06 batches/sec
  Train Batch 341/582, Loss: 3.3380, Speed: 2.21 batches/sec
  Train Batch 361/582, Loss: 3.2720, Speed: 2.25 batches/sec
  Train Batch 381/582, Loss: 3.2779, Speed: 1.88 batches/sec
  Train Batch 401/582, Loss: 3.3494, Speed: 2.26 batches/sec
  Train Batch 421/582, Loss: 3.3849, Speed: 2.44 batches/sec
  Train Batch 441/582, Loss: 3.3685, Speed: 2.23 batches/sec
  Train Batch 461/582, Loss: 3.3793, Speed: 1.98 batches/sec
  Train Batch 481/582, Loss: 3.3868, Speed: 2.35 batches/sec
  Train Batch 501/582, Loss: 3.2953, Speed: 1.92 batches/sec
  Train Batch 521/582, Loss: 3.3088, Speed: 2.07 batches/sec
  Train Batch 541/582, Loss: 3.2925, Speed: 2.43 batches/sec
  Train Batch 561/582, Loss: 3.2984, Speed: 1.77 batches/sec
  Train Batch 581/582, Loss: 3.3109, Speed: 1.86 batches/sec
Epoch 18 Training - Avg Loss: 3.3237, Time: 275.20 sec
Epoch 18 Validation - Avg Loss: 3.3409, Avg Accuracy: 0.1507, Time: 5.10 sec

Epoch 19/20
  Train Batch 1/582, Loss: 3.3998, Speed: 2.18 batches/sec
  Train Batch 21/582, Loss: 3.2851, Speed: 2.37 batches/sec
  Train Batch 41/582, Loss: 3.2875, Speed: 2.25 batches/sec
  Train Batch 61/582, Loss: 3.3167, Speed: 2.16 batches/sec
  Train Batch 81/582, Loss: 3.3343, Speed: 2.09 batches/sec
  Train Batch 101/582, Loss: 3.2971, Speed: 1.74 batches/sec
  Train Batch 121/582, Loss: 3.3103, Speed: 2.29 batches/sec
  Train Batch 141/582, Loss: 3.3691, Speed: 2.26 batches/sec
  Train Batch 161/582, Loss: 3.3337, Speed: 2.43 batches/sec
  Train Batch 181/582, Loss: 3.3091, Speed: 2.29 batches/sec
  Train Batch 201/582, Loss: 3.3826, Speed: 1.43 batches/sec
  Train Batch 221/582, Loss: 3.3397, Speed: 2.25 batches/sec
  Train Batch 241/582, Loss: 3.3197, Speed: 1.77 batches/sec
  Train Batch 261/582, Loss: 3.2913, Speed: 2.27 batches/sec
  Train Batch 281/582, Loss: 3.3356, Speed: 1.28 batches/sec
  Train Batch 301/582, Loss: 3.3610, Speed: 2.40 batches/sec
  Train Batch 321/582, Loss: 3.3036, Speed: 1.90 batches/sec
  Train Batch 341/582, Loss: 3.3429, Speed: 1.45 batches/sec
  Train Batch 361/582, Loss: 3.3029, Speed: 2.21 batches/sec
  Train Batch 381/582, Loss: 3.3384, Speed: 2.34 batches/sec
  Train Batch 401/582, Loss: 3.3257, Speed: 2.37 batches/sec
  Train Batch 421/582, Loss: 3.3822, Speed: 2.39 batches/sec
  Train Batch 441/582, Loss: 3.3428, Speed: 2.34 batches/sec
  Train Batch 461/582, Loss: 3.3475, Speed: 2.33 batches/sec
  Train Batch 481/582, Loss: 3.2918, Speed: 1.71 batches/sec
  Train Batch 501/582, Loss: 3.2949, Speed: 2.13 batches/sec
  Train Batch 521/582, Loss: 3.3232, Speed: 2.48 batches/sec
  Train Batch 541/582, Loss: 3.2980, Speed: 2.30 batches/sec
  Train Batch 561/582, Loss: 3.3077, Speed: 2.24 batches/sec
  Train Batch 581/582, Loss: 3.3667, Speed: 2.40 batches/sec
Epoch 19 Training - Avg Loss: 3.3236, Time: 274.19 sec
Epoch 19 Validation - Avg Loss: 3.3419, Avg Accuracy: 0.1507, Time: 4.82 sec

Epoch 20/20
  Train Batch 1/582, Loss: 3.3812, Speed: 2.29 batches/sec
  Train Batch 21/582, Loss: 3.3443, Speed: 2.09 batches/sec
  Train Batch 41/582, Loss: 3.3356, Speed: 2.23 batches/sec
  Train Batch 61/582, Loss: 3.3432, Speed: 2.36 batches/sec
  Train Batch 81/582, Loss: 3.3245, Speed: 2.27 batches/sec
  Train Batch 101/582, Loss: 3.3002, Speed: 2.30 batches/sec
  Train Batch 121/582, Loss: 3.3657, Speed: 2.46 batches/sec
  Train Batch 141/582, Loss: 3.2823, Speed: 2.24 batches/sec
  Train Batch 161/582, Loss: 3.2965, Speed: 2.40 batches/sec
  Train Batch 181/582, Loss: 3.3340, Speed: 2.42 batches/sec
  Train Batch 201/582, Loss: 3.3342, Speed: 2.53 batches/sec
  Train Batch 221/582, Loss: 3.3270, Speed: 2.38 batches/sec
  Train Batch 241/582, Loss: 3.3226, Speed: 2.47 batches/sec
  Train Batch 261/582, Loss: 3.3432, Speed: 2.22 batches/sec
  Train Batch 281/582, Loss: 3.3020, Speed: 2.19 batches/sec
  Train Batch 301/582, Loss: 3.3279, Speed: 2.11 batches/sec
  Train Batch 321/582, Loss: 3.3485, Speed: 2.07 batches/sec
  Train Batch 341/582, Loss: 3.3254, Speed: 2.27 batches/sec
  Train Batch 361/582, Loss: 3.3466, Speed: 1.52 batches/sec
  Train Batch 381/582, Loss: 3.3172, Speed: 1.89 batches/sec
  Train Batch 401/582, Loss: 3.2857, Speed: 1.98 batches/sec
  Train Batch 421/582, Loss: 3.3116, Speed: 2.01 batches/sec
  Train Batch 441/582, Loss: 3.3321, Speed: 2.49 batches/sec
  Train Batch 461/582, Loss: 3.3320, Speed: 2.44 batches/sec
  Train Batch 481/582, Loss: 3.3749, Speed: 2.59 batches/sec
  Train Batch 501/582, Loss: 3.3407, Speed: 2.03 batches/sec
  Train Batch 521/582, Loss: 3.3078, Speed: 1.91 batches/sec
  Train Batch 541/582, Loss: 3.3408, Speed: 1.38 batches/sec
  Train Batch 561/582, Loss: 3.3370, Speed: 2.10 batches/sec
  Train Batch 581/582, Loss: 3.2971, Speed: 2.12 batches/sec
Epoch 20 Training - Avg Loss: 3.3235, Time: 273.05 sec
Epoch 20 Validation - Avg Loss: 3.3402, Avg Accuracy: 0.1507, Time: 4.83 sec

--- Generating Sample Text for Metrics (using Nucleus Sampling) ---
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]
Shape of filtered_logits: [1 106]
Finite logits exist per row: [1]

Generated Sample:
ROMEO.. yoei 
atceeateefaet teutl tfrryrefme.slistfh, 
h his tetal tdnas  heftiu saiaigsoeae i  eeh  o  tdunnld r,uahore, 
trhu l. tygmrudu m.ntome nw rhu ls umo of eoodi,lce.slm an dymgrstget nah.wh
, nr  hio her
u erthwi  tra. .
. ltae ne
n
 c oi
hn t
inlso otlrtnofmadr . o

 
ni , n  ce mt iey
 ha .nfd

--- Calculating Metrics (on Test Set) ---

Metrics for Transformer Model (evaluated against Test Set):
Spelling Accuracy (words from test set): 0.28
Bigram Overlap with Test Set: 0.92
Trigram Diversity of Generated Sample: 0.94
Bigram Diversity of Generated Sample: 0.63
(DD2424) antonyzhang@MacBook-Pro DD2424-Project % 